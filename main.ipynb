{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Predecttive Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to the lack of existing real-world data, we will generate synthetic data to simulate the operating conditions and potential failures of industrial transformers and company laptops. The synthetic data will include various features such as temperature, vibration, load, ambient temperature, and humidity for transformers, and CPU usage, memory usage, disk health, and uptime for laptops.\n",
    "\n",
    "### The main steps in this notebook include:\n",
    "##### 1. **Data Augmentation:** Creating synthetic data that mimics real-world scenarios, including both normal operating conditions and potential failure conditions.\n",
    "##### 2. **Feature Engineering:** Creating additional features that help improve the predictive power of the model.\n",
    "##### 3. **Model Training:** Training machine learning models using the synthetic data to predict equipment failures.\n",
    "##### 4. **Real-time Data Integration:** Simulating real-time data collection and feeding it into the model for continuous predictions.\n",
    "##### 5. **Monitoring and Alerting:** Setting up mechanisms to monitor model predictions and generate alerts for potential failures.\n",
    "\n",
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "#### Synthetic data is generated at random within specfic ranges for each of the features. Additionally, a failure type label, and failure data are added to the data to simulate a fault. Finally, the data is shuffled to ensure that the data is not ordered in a way that would lead to a biased model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the number of samples\n",
    "numSamples = 10000\n",
    "\n",
    "# Generate equipment IDs\n",
    "laptop_ids = np.arange(1, numSamples + 1)\n",
    "\n",
    "# Generate normal operating conditions\n",
    "normalCpuUsage = np.random.uniform(10, 50, numSamples)\n",
    "normalMemoryUsage = np.random.uniform(30, 70, numSamples)\n",
    "normalDiskHealth = np.random.uniform(80, 100, numSamples)\n",
    "normalBatteryHealth = np.random.uniform(70, 100, numSamples)\n",
    "normalUptime = np.random.uniform(0, 100, numSamples)\n",
    "\n",
    "# Generate abnormal conditions (crashes)\n",
    "abnormalCpuUsage = np.random.uniform(70, 100, int(numSamples * 0.1))\n",
    "abnormalMemoryUsage = np.random.uniform(75, 100, int(numSamples * 0.1))\n",
    "abnormalDiskHealth = np.random.uniform(0, 50, int(numSamples * 0.1))\n",
    "abnormalBatteryHealth = np.random.uniform(0, 50, int(numSamples * 0.1))\n",
    "abnormalUptime = np.random.uniform(150, 200, int(numSamples * 0.1))\n",
    "\n",
    "# Concatenate normal and abnormal conditions\n",
    "cpuUsage = np.concatenate((normalCpuUsage, abnormalCpuUsage))\n",
    "memoryUsage = np.concatenate((normalMemoryUsage, abnormalMemoryUsage))\n",
    "diskHealth = np.concatenate((normalDiskHealth, abnormalDiskHealth))\n",
    "batteryHealth = np.concatenate((normalBatteryHealth, abnormalBatteryHealth))\n",
    "uptime = np.concatenate((normalUptime, abnormalUptime))\n",
    "\n",
    "# Create labels and estimate errors with threat levels\n",
    "labels = np.concatenate((np.zeros(numSamples), np.ones(int(numSamples * 0.1))))\n",
    "error_estimate, threat_level = [], []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:\n",
    "        if cpuUsage[i] > 85:\n",
    "            error_estimate.append(\"CPU High Usage\")\n",
    "            threat_level.append(\"High\")\n",
    "        elif cpuUsage[i] > 70:\n",
    "            error_estimate.append(\"CPU Temp High\")\n",
    "            threat_level.append(\"Critical\")\n",
    "        elif memoryUsage[i] > 85:\n",
    "            error_estimate.append(\"Memory Full\")\n",
    "            threat_level.append(\"Medium\")\n",
    "        elif diskHealth[i] < 50:\n",
    "            error_estimate.append(\"Disk Failure\")\n",
    "            threat_level.append(\"Critical\")\n",
    "        elif diskHealth[i] < 70:\n",
    "            error_estimate.append(\"Disk Full\")\n",
    "            threat_level.append(\"Medium\")\n",
    "        else:\n",
    "            error_estimate.append(\"Normal Operation\")\n",
    "            threat_level.append(\"Low\")\n",
    "    else:\n",
    "        error_estimate.append(\"Normal Operation\")\n",
    "        threat_level.append(\"Low\")\n",
    "\n",
    "# Create a DataFrame\n",
    "laptop_data = pd.DataFrame({\n",
    "    'laptop_id': np.concatenate((laptop_ids, laptop_ids[:int(numSamples * 0.1)])),\n",
    "    'cpu_usage': cpuUsage,\n",
    "    'memory_usage': memoryUsage,\n",
    "    'disk_health': diskHealth,\n",
    "    'battery_health': batteryHealth,\n",
    "    'uptime': uptime,\n",
    "    'system_crash': labels,\n",
    "    'error_estimate': error_estimate,\n",
    "    'threat_level': threat_level\n",
    "})\n",
    "\n",
    "# Shuffle the data\n",
    "laptop_data = laptop_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "laptop_data.to_csv('synthetic_laptop_data.csv', index=False)\n",
    "\n",
    "print(laptop_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laptop Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the number of samples\n",
    "numSamples = 10000\n",
    "\n",
    "# Generate equipment IDs\n",
    "laptop_ids = np.arange(1, numSamples + 1)\n",
    "\n",
    "# Generate normal operating conditions\n",
    "normalCpuUsage = np.random.uniform(10, 50, numSamples)\n",
    "normalMemoryUsage = np.random.uniform(30, 70, numSamples)\n",
    "normalDiskHealth = np.random.uniform(80, 100, numSamples)\n",
    "normalBatteryHealth = np.random.uniform(70, 100, numSamples)\n",
    "normalUptime = np.random.uniform(0, 100, numSamples)\n",
    "\n",
    "# Generate abnormal conditions (crashes)\n",
    "abnormalCpuUsage = np.random.uniform(70, 100, int(numSamples * 0.1))\n",
    "abnormalMemoryUsage = np.random.uniform(75, 100, int(numSamples * 0.1))\n",
    "abnormalDiskHealth = np.random.uniform(0, 50, int(numSamples * 0.1))\n",
    "abnormalBatteryHealth = np.random.uniform(0, 50, int(numSamples * 0.1))\n",
    "abnormalUptime = np.random.uniform(150, 200, int(numSamples * 0.1))\n",
    "\n",
    "# Concatenate normal and abnormal conditions\n",
    "cpuUsage = np.concatenate((normalCpuUsage, abnormalCpuUsage))\n",
    "memoryUsage = np.concatenate((normalMemoryUsage, abnormalMemoryUsage))\n",
    "diskHealth = np.concatenate((normalDiskHealth, abnormalDiskHealth))\n",
    "batteryHealth = np.concatenate((normalBatteryHealth, abnormalBatteryHealth))\n",
    "uptime = np.concatenate((normalUptime, abnormalUptime))\n",
    "\n",
    "# Create labels and estimate errors with threat levels\n",
    "labels = np.concatenate((np.zeros(numSamples), np.ones(int(numSamples * 0.1))))\n",
    "error_estimate, threat_level = [], []\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    if labels[i] == 1:\n",
    "        if cpuUsage[i] > 85:\n",
    "            error_estimate.append(\"CPU High Usage\")\n",
    "            threat_level.append(\"High\")\n",
    "        elif cpuUsage[i] > 70:\n",
    "            error_estimate.append(\"CPU Temp High\")\n",
    "            threat_level.append(\"Critical\")\n",
    "        elif memoryUsage[i] > 85:\n",
    "            error_estimate.append(\"Memory Full\")\n",
    "            threat_level.append(\"Medium\")\n",
    "        elif diskHealth[i] < 50:\n",
    "            error_estimate.append(\"Disk Failure\")\n",
    "            threat_level.append(\"Critical\")\n",
    "        elif diskHealth[i] < 70:\n",
    "            error_estimate.append(\"Disk Full\")\n",
    "            threat_level.append(\"Medium\")\n",
    "        else:\n",
    "            error_estimate.append(\"Normal Operation\")\n",
    "            threat_level.append(\"Low\")\n",
    "    else:\n",
    "        error_estimate.append(\"Normal Operation\")\n",
    "        threat_level.append(\"Low\")\n",
    "\n",
    "# Create a DataFrame\n",
    "laptop_data = pd.DataFrame({\n",
    "    'laptop_id': np.concatenate((laptop_ids, laptop_ids[:int(numSamples * 0.1)])),\n",
    "    'cpu_usage': cpuUsage,\n",
    "    'memory_usage': memoryUsage,\n",
    "    'disk_health': diskHealth,\n",
    "    'battery_health': batteryHealth,\n",
    "    'uptime': uptime,\n",
    "    'system_crash': labels,\n",
    "    'error_estimate': error_estimate,\n",
    "    'threat_level': threat_level\n",
    "})\n",
    "\n",
    "# Shuffle the data\n",
    "laptop_data = laptop_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "laptop_data.to_csv('synthetic_laptop_data.csv', index=False)\n",
    "\n",
    "print(laptop_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Modles for Predictive Maintenance\n",
    "\n",
    "### Here models will be trained on both the laptop data and the Transformers data. THe models will then be dumped (saved) in order to be used later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load synthetic transformer data\n",
    "transformer_data = pd.read_csv('synthetic_transformer_data.csv')\n",
    "\n",
    "# Defining features and target\n",
    "features = ['temperature', 'vibration', 'load', 'ambient_temp', 'humidity']\n",
    "target = 'failure'\n",
    "\n",
    "X = transformer_data[features]\n",
    "y = transformer_data[target]\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using Random Forest\n",
    "transformer_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "transformer_model.fit(X_train, y_train)\n",
    "\n",
    "#Save the model and ouput a classification report\n",
    "joblib.dump(transformer_model, 'transformer_model.pkl')\n",
    "y_pred = transformer_model.predict(X_test)\n",
    "print(\"Transformer Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Laptop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load synthetic laptop data\n",
    "laptop_data = pd.read_csv('synthetic_laptop_data.csv')\n",
    "\n",
    "# Define features and target\n",
    "features = ['cpu_usage', 'memory_usage', 'disk_health', 'battery_health', 'uptime']\n",
    "target = 'system_crash'\n",
    "\n",
    "X = laptop_data[features]\n",
    "y = laptop_data[target]\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train using Logistic Regression model\n",
    "laptop_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "laptop_model.fit(X_train, y_train)\n",
    "\n",
    "#Save the model and ouput a classification report\n",
    "joblib.dump(laptop_model, 'laptop_model.pkl')\n",
    "y_pred = laptop_model.predict(X_test)\n",
    "print(\"Laptop Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
