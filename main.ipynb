{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning for Predecttive Maintenance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Due to the lack of existing real-world data, we will generate synthetic data to simulate the operating conditions and potential failures of industrial transformers and company laptops. The synthetic data will include various features such as temperature, vibration, load, ambient temperature, and humidity for transformers, and CPU usage, memory usage, disk health, and uptime for laptops.\n",
    "\n",
    "### The main steps in this notebook include:\n",
    "##### 1. **Data Augmentation:** Creating synthetic data that mimics real-world scenarios, including both normal operating conditions and potential failure conditions.\n",
    "##### 2. **Feature Engineering:** Creating additional features that help improve the predictive power of the model.\n",
    "##### 3. **Model Training:** Training machine learning models using the synthetic data to predict equipment failures.\n",
    "##### 4. **Real-time Data Integration:** Simulating real-time data collection and feeding it into the model for continuous predictions.\n",
    "##### 5. **Monitoring and Alerting:** Setting up mechanisms to monitor model predictions and generate alerts for potential failures.\n",
    "\n",
    "## Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation\n",
    "#### Synthetic data is generated at random within specfic ranges for each of the features. Additionally, a failure type label, and failure data are added to the data to simulate a fault. Finally, the data is shuffled to ensure that the data is not ordered in a way that would lead to a biased model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the number of samples\n",
    "numSamples = 10000\n",
    "\n",
    "# Generate equipment IDs\n",
    "equipment_ids = np.arange(1, numSamples + 1)\n",
    "\n",
    "# Generate normal operating conditions\n",
    "normalTemperature = np.random.uniform(60, 80, numSamples)\n",
    "normalVibration = np.random.uniform(0, 0.1, numSamples)\n",
    "normalLoad = np.random.uniform(30, 70, numSamples)\n",
    "normalAmbient_temp = np.random.uniform(20, 40, numSamples)\n",
    "normalHumidity = np.random.uniform(30, 70, numSamples)\n",
    "\n",
    "# Generate abnormal conditions (failures)\n",
    "abnormalTemperature = np.random.uniform(80, 100, int(numSamples * 0.1))\n",
    "abnormalVibration = np.random.uniform(0.1, 0.5, int(numSamples * 0.1))\n",
    "abnormalLoad = np.random.uniform(70, 100, int(numSamples * 0.1))\n",
    "abnormalAmbientTemp = np.random.uniform(40, 60, int(numSamples * 0.1))\n",
    "abnormalHumidity = np.random.uniform(70, 100, int(numSamples * 0.1))\n",
    "\n",
    "temperature = np.concatenate((normalTemperature, abnormalTemperature))\n",
    "vibration = np.concatenate((normalVibration, abnormalVibration))\n",
    "load = np.concatenate((normalLoad, abnormalLoad))\n",
    "ambientTemp = np.concatenate((normalAmbient_temp, abnormalAmbientTemp))\n",
    "humidity = np.concatenate((normalHumidity, abnormalHumidity))\n",
    "\n",
    "# Create categorical labels based on the conditions\n",
    "def categorizeFailure(temp, vib, load):\n",
    "    if temp > 80:\n",
    "        return \"Insulation Breakdown or Cooling System Failure\"\n",
    "    elif vib > 0.1:\n",
    "        return \"Mechanical Wear or Loose Components\"\n",
    "    elif load > 70:\n",
    "        return \"Overload or Imbalanced Load\"\n",
    "    else:\n",
    "        return \"Normal Operation\"\n",
    "\n",
    "failureCategory = [categorizeFailure(t, v, l) for t, v, l in zip(temperature, vibration, load)]\n",
    "\n",
    "transformer_data = pd.DataFrame({\n",
    "    'equipment_id': equipment_ids,\n",
    "    'temperature': temperature,\n",
    "    'vibration': vibration,\n",
    "    'load': load,\n",
    "    'ambient_temp': ambientTemp,\n",
    "    'humidity': humidity,\n",
    "    'failure_category': failureCategory\n",
    "})\n",
    "\n",
    "# Shuffle data\n",
    "transformer_data = transformer_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Save data\n",
    "transformer_data.to_csv('synthetic_transformer_data.csv', index=False)\n",
    "\n",
    "print(transformer_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laptop Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define the number of samples\n",
    "numSamples = 10000\n",
    "\n",
    "# Generate equipment IDs\n",
    "laptop_ids = np.arange(1, numSamples + 1)\n",
    "\n",
    "# Generate normal operating conditions\n",
    "normalCpuUsage = np.random.uniform(10, 50, numSamples)\n",
    "normalMemoryUsage = np.random.uniform(30, 70, numSamples)\n",
    "normalDiskHealth = np.random.uniform(80, 100, numSamples)\n",
    "normalBatteryHealth = np.random.uniform(70, 100, numSamples)\n",
    "normalUptime = np.random.uniform(0, 100, numSamples)\n",
    "\n",
    "# Generate abnormal conditions (crashes)\n",
    "abnormalCpuUsage = np.random.uniform(70, 100, int(numSamples * 0.1))\n",
    "abnormalMemoryUsage = np.random.uniform(75, 100, int(numSamples * 0.1))\n",
    "abnormalDiskHealth = np.random.uniform(0, 50, int(numSamples * 0.1))\n",
    "abnormalBatteryHealth = np.random.uniform(0, 50, int(numSamples * 0.1))\n",
    "abnormalUptime = np.random.uniform(150, 200, int(numSamples * 0.1))\n",
    "\n",
    "cpuUsage = np.concatenate((normalCpuUsage, abnormalCpuUsage))\n",
    "memoryUsage = np.concatenate((normalMemoryUsage, abnormalMemoryUsage))\n",
    "diskHealth = np.concatenate((normalDiskHealth, abnormalDiskHealth))\n",
    "batteryHealth = np.concatenate((normalBatteryHealth, abnormalBatteryHealth))\n",
    "uptime = np.concatenate((normalUptime, abnormalUptime))\n",
    "\n",
    "# Create categorical labels based on the conditions\n",
    "def categorize_issue(cpu, mem, disk):\n",
    "    if cpu > 85:\n",
    "        return \"CPU Overload or Thermal Throttling\"\n",
    "    elif cpu > 70:\n",
    "        return \"CPU Failure or Cooling System Degradation\"\n",
    "    elif mem > 85:\n",
    "        return \"Memory Leak or Insufficient RAM\"\n",
    "    elif disk < 50:\n",
    "        return \"Imminent Disk Failure or Bad Sectors\"\n",
    "    elif disk < 70:\n",
    "        return \"Disk Capacity Exhaustion or Fragmentation\"\n",
    "    else:\n",
    "        return \"Normal Operation\"\n",
    "\n",
    "issue_category = [categorize_issue(c, m, d) for c, m, d in zip(cpuUsage, memoryUsage, diskHealth)]\n",
    "\n",
    "laptop_data = pd.DataFrame({\n",
    "    'laptop_id': laptop_ids,\n",
    "    'cpu_usage': cpuUsage,\n",
    "    'memory_usage': memoryUsage,\n",
    "    'disk_health': diskHealth,\n",
    "    'battery_health': batteryHealth,\n",
    "    'uptime': uptime,\n",
    "    'issue_category': issue_category\n",
    "})\n",
    "\n",
    "# Shuffle data\n",
    "laptop_data = laptop_data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "laptop_data.to_csv('synthetic_laptop_data.csv', index=False)\n",
    "\n",
    "print(laptop_data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Modles for Predictive Maintenance\n",
    "\n",
    "### Here models will be trained on both the laptop data and the Transformers data. THe models will then be dumped (saved) in order to be used later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training transformer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load synthetic transformer data\n",
    "transformer_data = pd.read_csv('synthetic_transformer_data.csv')\n",
    "\n",
    "# Defining features and target\n",
    "features = ['temperature', 'vibration', 'load', 'ambient_temp', 'humidity']\n",
    "target = 'failure'\n",
    "\n",
    "X = transformer_data[features]\n",
    "y = transformer_data[target]\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the model using Random Forest\n",
    "transformer_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "transformer_model.fit(X_train, y_train)\n",
    "\n",
    "#Save the model and ouput a classification report\n",
    "joblib.dump(transformer_model, 'transformer_model.pkl')\n",
    "y_pred = transformer_model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "with open('transformer_classification_report.txt', 'w') as file:\n",
    "    file.write(report)\n",
    "print(\"Transformer Model Classification Report:\")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Laptop model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Load synthetic laptop data\n",
    "laptop_data = pd.read_csv('synthetic_laptop_data.csv')\n",
    "\n",
    "# Define features and target\n",
    "features = ['cpu_usage', 'memory_usage', 'disk_health', 'battery_health', 'uptime']\n",
    "target = 'system_crash'\n",
    "\n",
    "X = laptop_data[features]\n",
    "y = laptop_data[target]\n",
    "\n",
    "# Split data \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train using Logistic Regression model\n",
    "laptop_model = LogisticRegression(random_state=42, max_iter=1000)\n",
    "laptop_model.fit(X_train, y_train)\n",
    "\n",
    "#Save the model and ouput a classification report\n",
    "joblib.dump(laptop_model, 'laptop_model.pkl')\n",
    "y_pred = laptop_model.predict(X_test)\n",
    "report = classification_report(y_test, y_pred)\n",
    "with open('laptop_classification_report.txt', 'w') as file:\n",
    "    file.write(report)\n",
    "print(\"Laptop Model Classification Report:\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
